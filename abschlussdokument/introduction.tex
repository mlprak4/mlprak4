%!TEX root = bare_conf.tex

\section{Introduction}

In the last couple of years autonomous driving became a hot discussed topic. The approaches used for autonomous driving generally fall in one of two categories: mediated perception or behaviour reflex. The first one treats the whole system as a combination of multiple sub-systems. Each sub-system takes responsibility for one specific task, such as lane detection, traffic light detection, pedestrian detection and more. The features obtained from each sub-system are then fused together to form a single decision. Behaviour reflex approaches do not use mediated sub-systems, instead decisions are made directly based on the raw sensor data.

Deep learning has proven to be a powerful tool for image processing, especially convolutional neural networks (CNN), which are able to learn a high level abstraction of the input data by extracting features of different levels. Reinforcement learning is a powerful tool to address problems in decision making without knowing the underlying model. Deep-Q-learning (DQN) combines both of these two methods, by approximating the Q-function of a Q-learning approach with a deep neural network. First introduced in \cite{Mnih13} by Mnih et al., human level results for playing Atari games were achieved. Yu et al. \cite{yudeep} had success in the autonomous control of a vehicle in a Java Script based game using DQN and Chen et al. \cite{chen2015deepdriving} made advances in the complexity of the environment that could be learned. In this paper we present a behaviour reflex approach using DQN to teach an autonomous vehicle to drive in a 3D simulation. 

In Section \ref{sec:setup} we will introduce the fundamental architecture and setup of our system. The approach, including network, training and reward function, will be discussed in section \ref{sec:approach}. Next we will evaluate our approach in \ref{sec:evaluation}. Lastly, in \ref{sec:discussion} we will discuss our work and present an outlook for further development.